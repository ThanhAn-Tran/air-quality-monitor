import anthropic
from cassandra_CRUD import PollutionDataProcessor
import tensorflow as tf
import numpy as np
from config import Config

class PollutionQueryHandler:
    def __init__(self, api_key):
        self.client = anthropic.Client(api_key=api_key)
        self.tools = [
            {
                "name": "query_pollution_data_openai",
                "description": "Ng∆∞·ªùi d√πng mu·ªën truy v·∫•n d·ªØ li·ªáu √¥ nhi·ªÖm theo ng√†y/th√°ng/nƒÉm",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "year": {"type": "integer", "description": "NƒÉm c·∫ßn truy v·∫•n"},
                        "month": {"type": "integer", "description": "Th√°ng c·∫ßn truy v·∫•n"},
                        "day": {"type": "integer", "description": "Ng√†y c·∫ßn truy v·∫•n"},
                    },
                    "required": ["year", "month", "day"]
                },
            },
            {
                "name": "predict_pollution_level",
                "description": "D·ª± ƒëo√°n m·ª©c ƒë·ªô √¥ nhi·ªÖm d·ª±a tr√™n th√¥ng s·ªë m√¥i tr∆∞·ªùng v√† th·ªùi gian.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "Day": {"type": "integer", "description": "Ng√†y trong th√°ng"},
                        "Month": {"type": "integer", "description": "Th√°ng trong nƒÉm"},
                        "Year": {"type": "integer", "description": "NƒÉm c·ªßa d·ªØ li·ªáu"},
                        "Hour": {"type": "integer", "description": "Gi·ªù c·ªßa d·ªØ li·ªáu"},
                        "PT08_S1_CO": {"type": "number", "description": "N·ªìng ƒë·ªô CO ƒëo t·ª´ c·∫£m bi·∫øn PT08.S1 "},
                        "C6H6_GT": {"type": "number", "description": "N·ªìng ƒë·ªô Benzen "},
                        "PT08_S5_O3": {"type": "number", "description": "N·ªìng ƒë·ªô O3 ƒëo t·ª´ c·∫£m bi·∫øn PT08.S5 "},
                        "PT08_S2_NMHC": {"type": "number",
                                         "description": "N·ªìng ƒë·ªô NMHC ƒëo t·ª´ c·∫£m bi·∫øn PT08.S2"},
                        "PT08_S4_NO2": {"type": "number", "description": "N·ªìng ƒë·ªô NO2 ƒëo t·ª´ c·∫£m bi·∫øn PT08.S4"}
                    },
                    "required": [
                        "Day", "Month", "Year", "Hour",
                        "PT08_S1_CO", "C6H6_GT", "PT08_S5_O3",
                        "PT08_S2_NMHC", "PT08_S4_NO2"
                    ]
                }
            },

            {
                "name": "insert_data_to_database",
                "description": "Ng∆∞·ªùi d√πng mu·ªën th√™m d·ªØ li·ªáu √¥ nhi·ªÖm v√†o database.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "Day": {"type": "integer", "description": "Ng√†y c·ªßa d·ªØ li·ªáu (1-31)"},
                        "Month": {"type": "integer", "description": "Th√°ng c·ªßa d·ªØ li·ªáu (1-12)"},
                        "Year": {"type": "integer", "description": "NƒÉm c·ªßa d·ªØ li·ªáu (v√≠ d·ª•: 2024)"},
                        "Hour": {"type": "integer", "description": "Gi·ªù c·ªßa d·ªØ li·ªáu (0-23)"},
                        "PT08_S1_CO": {"type": "number", "description": "N·ªìng ƒë·ªô PT08.S1 (CO) "},
                        "C6H6_GT": {"type": "number", "description": "N·ªìng ƒë·ªô Benzen "},
                        "PT08_S5_O3": {"type": "number", "description": "N·ªìng ƒë·ªô PT08.S5 (O3) "},
                        "PT08_S2_NMHC": {"type": "number", "description": "N·ªìng ƒë·ªô PT08.S2 (NMHC)"},
                        "PT08_S4_NO2": {"type": "number", "description": "N·ªìng ƒë·ªô PT08.S4 (NO2) "},
                        "AQI_Label": {
                            "type": "integer",
                            "description": "Ch·ªâ s·ªë ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠: 0 (T·ªët), 1 (Trung b√¨nh), 2 (K√©m), 3 (X·∫•u), 4 (Nguy h·∫°i)"
                        }
                    },
                    "required": ["Day", "Month", "Year", "Hour", "PT08_S1_CO", "C6H6_GT", "PT08_S5_O3", "PT08_S2_NMHC",
                                 "PT08_S4_NO2", "AQI_Label"]
                }
            },

            {
                "name": "statistical_analysis",
                "description": "Th·ª±c hi·ªán ph√¢n t√≠ch th·ªëng k√™ m·ª©c ƒë·ªô √¥ nhi·ªÖm",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "stat_type": { "type": "string", "description": "Lo·∫°i th·ªëng k√™ (mean, median, mode, max, min)"},
                        "start_day": {"type": "integer","description": "Ng√†y b·∫Øt ƒë·∫ßu (1-31)"},
                        "start_month": {"type": "integer","description": "Th√°ng b·∫Øt ƒë·∫ßu (1-12)"},
                        "end_day": {"type": "integer","description": "Ng√†y k·∫øt th√∫c (1-31)"},
                        "end_month": {"type": "integer","description": "Th√°ng k·∫øt th√∫c (1-12)"},
                        "year": {"type": "integer","description": "NƒÉm ph√¢n t√≠ch"}
                    },
                    "required": ["stat_type", "start_day", "start_month", "end_day", "end_month", "year"]
                }
            }
        ]

    def query_pollution_data_openai(self, year=None, month=None, day=None):
        query_params = {
            "year": year,
            "month": month,
            "day": day,
        }
        print("ƒêang truy v·∫•n d·ªØ li·ªáu v·ªõi:", query_params)
        processor = PollutionDataProcessor(["127.0.0.1"], "pollution_db")
        try:
            data = processor.query_pollution_data(**query_params)
            processor.close_connection()
            if data.empty:
                return {"message": "Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p v·ªõi truy v·∫•n."}
            return data.to_dict(orient="records")
        except Exception as e:
            return {"error": f"L·ªói truy v·∫•n Cassandra: {str(e)}"}

    def insert_data_to_database(self, Day, Month, Year, Hour, PT08_S1_CO, C6H6_GT, PT08_S5_O3, PT08_S2_NMHC,
                                PT08_S4_NO2, AQI_Label):
        processor = PollutionDataProcessor(["127.0.0.1"], "pollution_db")
        try:
            corrected_data = {
                "Day": Day,
                "Month": Month,
                "Year": Year,
                "Hour": Hour,
                "PT08_S1_CO": PT08_S1_CO,
                "C6H6_GT": C6H6_GT,
                "PT08_S5_O3": PT08_S5_O3,
                "PT08_S2_NMHC": PT08_S2_NMHC,
                "PT08_S4_NO2": PT08_S4_NO2,
                "AQI_Label": AQI_Label
            }

            insert_status = processor.add_pollution_data_from_nlp(**corrected_data)

            if insert_status == "inserted":
                return {"message": "D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c th√™m v√†o database."}
            elif insert_status == "exists":
                return {"message": "D·ªØ li·ªáu ƒë√£ t·ªìn t·∫°i, kh√¥ng c·∫ßn th√™m."}
            else:
                return {"error": "Kh√¥ng r√µ tr·∫°ng th√°i ch√®n d·ªØ li·ªáu."}
        except Exception as e:
            return {"error": f"L·ªói khi ch√®n d·ªØ li·ªáu: {str(e)}"}

    def predict_pollution_level(self, Day, Month, Year, Hour, PT08_S1_CO, C6H6_GT, PT08_S5_O3, PT08_S2_NMHC, PT08_S4_NO2):
        try:
            self.model = tf.keras.models.load_model("model_ML/air_quality_model.h5")

            input_features = np.array([[Day, Month, Year, Hour, PT08_S1_CO, C6H6_GT, PT08_S5_O3, PT08_S2_NMHC, PT08_S4_NO2]])

            prediction = self.model.predict(input_features)
            predicted_class = int(np.argmax(prediction, axis=1)[0])

            pollution_levels = ["Th·∫•p", "Trung b√¨nh", "Cao", "Nguy hi·ªÉm", "R·∫•t nguy h·∫°i"]
            predicted_label = pollution_levels[predicted_class]
            return {"pollution_level": predicted_class, "description": predicted_label}
        except Exception as e:
            return {"error": f"L·ªói d·ª± ƒëo√°n: {str(e)}"}


    def statistical_analysis(self, stat_type: str, start_day: int, start_month: int, end_day: int, end_month: int,
                             year: int):
        processor = PollutionDataProcessor(["127.0.0.1"], "pollution_db")
        time_range = {
            "start_day": start_day,
            "start_month": start_month,
            "end_day": end_day,
            "end_month": end_month,
            "year": year
        }

        data = processor.query_pollution_data_for_stats(time_range)

        if not data:
            return {"message": "Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ th·ªëng k√™"}

        columns = ['PT08_S1_CO', 'C6H6_GT', 'PT08_S5_O3', 'PT08_S2_NMHC', 'PT08_S4_NO2', 'AQI_Label']
        data_dicts = [dict(zip(columns, row)) for row in data]

        data_array = np.array([[row[col] for col in columns] for row in data_dicts])

        stats_result = {}
        if stat_type == "mean":
            stats_result = dict(zip(columns, np.mean(data_array, axis=0)))
        elif stat_type == "median":
            stats_result = dict(zip(columns, np.median(data_array, axis=0)))
        elif stat_type == "std":
            stats_result = dict(zip(columns, np.std(data_array, axis=0)))
        elif stat_type == "max":
            stats_result = dict(zip(columns, np.max(data_array, axis=0)))
        elif stat_type == "min":
            stats_result = dict(zip(columns, np.min(data_array, axis=0)))
        elif stat_type == "count":
            stats_result = {"Total Records": len(data)}
        else:
            stats_result = {"error": "Lo·∫°i th·ªëng k√™ kh√¥ng h·ª£p l·ªá"}

        return {"stat_type": stat_type, "result": stats_result}

    def call_claude_function(self, prompt):
        try:
            response = self.client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=1000,
                tools=self.tools,
                messages=[{"role": "user", "content": prompt}],
            )

            print(f'Claude Raw Response: {response}')

            if not response or not isinstance(response.content, list) or len(response.content) == 0:
                return {"error": "Kh√¥ng c√≥ ph·∫£n h·ªìi h·ª£p l·ªá t·ª´ Claude."}

            if isinstance(response.content, list) and response.content:
                tool_use_block = next((block for block in response.content if block.type == "tool_use"), None)

                if getattr(tool_use_block, 'type', None) == 'tool_use':
                    function_name = getattr(tool_use_block, 'name', None)
                    arguments = getattr(tool_use_block, 'input', {})

                    if not function_name:
                        return {"error": "Kh√¥ng t√¨m th·∫•y t√™n h√†m."}

                    if not isinstance(arguments, dict):
                        arguments = {}

                    function_map = {
                        "query_pollution_data_openai": self.query_pollution_data_openai,
                        "predict_pollution_level": self.predict_pollution_level,
                        "insert_data_to_database": self.insert_data_to_database,
                        "statistical_analysis": self.statistical_analysis
                    }

                    if function_name in function_map:
                        result = function_map[function_name](**arguments)
                    else:
                        result = {"error": "H√†m kh√¥ng h·ª£p l·ªá."}

                    print(f'K·∫øt qu·∫£ t·ª´ h√†m "{function_name}": {result}, v·ªõi tham s·ªë: {arguments}')
                    return result

        except Exception as e:
            return {"error": f"L·ªói khi g·ªçi Claude: {str(e)}"}

        return {"error": "D·ªØ li·ªáu nh·∫≠p v√†o kh√¥ng h·ª£p l·ªá."}

    def rewrite_result_with_advice(self, result, source=None):

        if source is None:
            if isinstance(result, list):
                source = "query"
            elif isinstance(result, dict) and "pollution_level" in result:
                source = "predict"
            elif isinstance(result, dict) and result.get("message") in [
                                                                        "H√†m ƒë√£ ƒë∆∞·ª£c th·ª±c thi!",
                                                                        "D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c th√™m v√†o database.",
                                                                        "ƒê√£ th√™m d·ªØ li·ªáu th√†nh c√¥ng"]:
                source = "insert"
            elif isinstance(result, dict) and result.get("stat_type") in ["mean", "median", "max","min","count","std"]:
                source = "stats"
        else:
                source = "unknown"
        print("Source:", source)
        if source == "query":
            rewriting_prompt = f"""
            B·∫°n l√† chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu m√¥i tr∆∞·ªùng.   
            D·ªØ li·ªáu c·∫£m bi·∫øn:
            {result}  
            Y√™u c·∫ßu ƒë·∫ßu ra:
            - Ng√†y truy v·∫•n.
            - Ki·ªÉm tra c√≥ d·ªØ li·ªáu kh√¥ng. T·ª´ ch·ªëi tr·∫£ l·ªùi n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu.
            - Ch·ªâ hi·ªÉn th·ªã gi·ªù v√† m·ª©c ƒë·ªô √¥ nhi·ªÖm. 
            - Kh√¥ng vi·∫øt di·ªÖn gi·∫£i d√†i d√≤ng.
            - Kh√¥ng c·∫ßn nh·∫≠n x√©t.

            C√°c m·ª©c ƒë·ªô nhi·ªÖm g·ªìm: 0: th·∫•p, 1: trung b√¨nh, 2: cao, 3: r·∫•t cao, 4: nguy h·∫°i
            
            V√≠ d·ª• ƒë·∫ßu ra mong mu·ªën (n·∫øu c√≥ d·ªØ li·ªáu √¥ nhi·ªÖm):
            Ng√†y 20 th√°ng 5 nƒÉm 2004:
            - 0h,2h,3h,4h,20h,21h,22h,23h: √î nhi·ªÖm th·∫•p (0)  
            - 1h,5h,8h,13h,14h: √î nhi·ªÖm cao (2)  
            - 6h,7h,9h,10h,11h,12h: √î nhi·ªÖm r·∫•t cao (3)  
            - 15h,16h,17h,18h,19h: √î nhi·ªÖm m·ª©c nguy h·∫°i (4)
            """
        elif source == "predict":
            rewriting_prompt = f"""
            H√£y di·ªÖn gi·∫£i k·∫øt qu·∫£ n√†y m·ªôt c√°ch ng·∫Øn g·ªçn, ch·ªâ n√™u ra m·ª©c ƒë·ªô √¥ nhi·ªÖm (n·∫øu c√≥) v√† ƒë∆∞a ra l·ªùi khuy√™n cho ng∆∞·ªùi d√πng v·ªÅ vi·ªác c√≥ n√™n ra ngo√†i hay c·∫ßn √°p d·ª•ng c√°c bi·ªán ph√°p b·∫£o v·ªá. 
            N·∫øu k·∫øt qu·∫£ ch·ª©a kh√≥a "pollution_level" ho·∫∑c "description", h√£y s·ª≠ d·ª•ng c√°c th√¥ng tin ƒë√≥ ƒë·ªÉ ƒë∆∞a ra l·ªùi khuy√™n. 
            C√≥ th·ªÉ vi·∫øt l·∫°i l·ªùi khuy√™n theo c√°c m·ª©c ƒë·ªô √¥ nhi·ªÖm nh∆∞ sau:
            - N·∫øu √¥ nhi·ªÖm th·∫•p (0, "Th·∫•p"): "Ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ t·ªët l√† m·ªôt ng√†y tuy·ªát v·ªùi ƒë·ªÉ ra ngo√†i."
            - N·∫øu √¥ nhi·ªÖm trung b√¨nh (1, "Trung b√¨nh"): "Ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ ·ªïn ƒë·ªãnh, nh∆∞ng h√£y quan t√¢m b·∫£n th√¢n khi ra ngo√†i."
            - N·∫øu √¥ nhi·ªÖm cao (2, "Cao"): "Ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ k√©m, n√™n h·∫°n ch·∫ø ra ngo√†i v√† ƒëeo kh·∫©u trang."
            - N·∫øu √¥ nhi·ªÖm nguy hi·ªÉm (3, "Nguy hi·ªÉm"): "Ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ r·∫•t k√©m, h·∫°n ch·∫ø ra ngo√†i v√† tu√¢n th·ªß h∆∞·ªõng d·∫´n b·∫£o v·ªá s·ª©c kh·ªèe."
            - N·∫øu √¥ nhi·ªÖm c·ª±c cao (4, "R·∫•t nguy h·∫°i"): "C·∫£nh b√°o √¥ nhi·ªÖm c·ª±c cao, h√£y ·ªü nh√† v√† th·ª±c hi·ªán c√°c bi·ªán ph√°p an to√†n."

            ƒê∆∞a ra k·∫øt qu·∫£ theo ƒë·ªãnh d·∫°ng:
            [M·ª©c ƒë·ªô] - [L·ªùi khuy√™n]

            D∆∞·ªõi ƒë√¢y l√† k·∫øt qu·∫£ h·ªá th·ªëng:
            {result}
            """
        elif source == "insert":
            rewriting_prompt = f"""
            Th√¥ng b√°o cho ng∆∞·ªùi d√πng v·ªÅ vi·ªác d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c th√™m v√†o c∆° s·ªü d·ªØ li·ªáu v√† ng∆∞·ªùi d√πng c√≥ th·ªÉ ki·ªÉm tra l·∫°i th√¥ng tin ƒë√£ th√™m b·∫±ng c√°ch th·ª≠ truy v·∫•n l·∫°i.
            """
        elif source == "stats":
            stat_type = result.get("stat_type", None)
            stats_data = result.get("result", {})

            if stat_type in ["mean", "median", "std", "max", "min"]:
                formatted_data = "\n".join([f"- {key} : {value}" for key, value in stats_data.items()])

                if stat_type == "mean":
                    rewriting_prompt = f"""
                    Ghi l·∫°i t·∫•t c·∫£ k·∫øt qu·∫£ th·ªëng k√™ trung b√¨nh (`mean`) c·ªßa c√°c ch·ªâ s·ªë √¥ nhi·ªÖm v√† kh√¥ng nh·∫≠n x√©t:
                    {formatted_data}
                    """
                elif stat_type == "median":
                    rewriting_prompt = f"""
                     Ghi l·∫°i t·∫•t c·∫£ k·∫øt qu·∫£ th·ªëng k√™ trung v·ªã (`median`) c·ªßa c√°c ch·ªâ s·ªë √¥ nhi·ªÖm v√† kh√¥ng nh·∫≠n x√©t:
                    {formatted_data}
                    """
                elif stat_type == "std":
                    rewriting_prompt = f"""
                    Ghi l·∫°i t·∫•t c·∫£ k·∫øt qu·∫£ ƒë·ªô l·ªách chu·∫©n (`std`) c·ªßa c√°c ch·ªâ s·ªë √¥ nhi·ªÖm v√† kh√¥ng nh·∫≠n x√©t:
                    {formatted_data}
                    """
                elif stat_type == "max":
                    rewriting_prompt = f"""
                    Ghi l·∫°i t·∫•t c·∫£ m·ª©c ƒë·ªô √¥ nhi·ªÖm cao nh·∫•t (`max`) ƒë∆∞·ª£c ghi nh·∫≠n trong kho·∫£ng th·ªùi gian ƒë√£ ch·ªçn v√† kh√¥ng nh·∫≠n x√©t:
                    {formatted_data}
                    """

                elif stat_type == "min":
                    rewriting_prompt = f"""
                    Ghi l·∫°i t·∫•t c·∫£ m·ª©c ƒë·ªô √¥ nhi·ªÖm th·∫•p nh·∫•t (`min`) ƒë∆∞·ª£c ghi nh·∫≠n trong kho·∫£ng th·ªùi gian ƒë√£ ch·ªçn v√† kh√¥ng nh·∫≠n x√©t:
                    {formatted_data}
                    """
            elif stat_type == "count":
                total_records = stats_data.get("Total Records", 0)
                rewriting_prompt = f"""
                Vi·∫øt l·∫°i t·ªïng s·ªë b·∫£n ghi d·ªØ li·ªáu (`count`):{total_records}
                """
            else:

                rewriting_prompt = "D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng th·ªÉ di·ªÖn gi·∫£i."

        else:
            return result
        try:
            print("Rewriting Prompt:", rewriting_prompt)

            response = self.client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=500,
                messages=[{"role": "user", "content": rewriting_prompt}],
            )
            print(result)
            if hasattr(response, 'content') and isinstance(response.content, list):
                text_blocks = [block.text for block in response.content if getattr(block, 'type', None) == 'text']
                return "\n".join(text_blocks)
        except Exception as e:
            return f"L·ªói khi vi·∫øt l·∫°i k·∫øt qu·∫£: {str(e)}"
        return "Kh√¥ng th·ªÉ vi·∫øt l·∫°i k·∫øt qu·∫£."

if __name__ == "__main__":
    # Validate configuration before starting
    Config.validate_config()
    
    handler = PollutionQueryHandler(Config.ANTHROPIC_API_KEY)
    prompt = input("üìù Nh·∫≠p truy v·∫•n c·ªßa b·∫°n: ")
    result = handler.call_claude_function(prompt)
    final_result = handler.rewrite_result_with_advice(result)
    print(final_result)
